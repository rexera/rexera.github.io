---
title: "[IJCNN 2025] PanelTR: Zero-Shot Table Reasoning Through Multi-Agent Scientific Discussion"
date: 2025-06-30
categories: [Technical, MAS]
---

Ever wonder how AI can tackle complex table reasoningâ€”like answering questions from financial reports or verifying facts in scientific papersâ€”without any prior training? In this paper, **PanelTR**, I explore exactly that!

Instead of relying on heavy data annotation or complex neural architectures, I designed a **multi-agent framework** where five LLM-powered scientist personasâ€”like **Einstein**, **Newton**, and **Curie**â€”work together to analyze, debate, and refine answers through a structured scientific process:

- ðŸ” **Investigation**: Each scientist breaks down the problem.
- ðŸ‘ï¸ **Self-Review**: They critique their own reasoning.
- ðŸ§  **Peer-Review**: They discuss and vote on the best answer.

The result? **PanelTR outperforms standard LLMs** and even **rivals supervised models**â€”all in a **zero-shot setting** (no task-specific training required. Itâ€™s like having a mini-science panel inside your computer.

[![arXiv](https://img.shields.io/badge/arXiv-2508.06110-b31b1b.svg)](https://arxiv.org/abs/2508.06110)

*Abstract:*  
> Table reasoning, including tabular QA and fact verification, often depends on annotated data or complex data augmentation, limiting flexibility and generalization. We introduce PanelTR, a framework utilizing LLM agent scientists for robust table reasoning through a structured scientific approach. Experiments across four benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully supervised models, all while remaining independent of training data.
